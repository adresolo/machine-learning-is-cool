{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81456dd",
   "metadata": {},
   "source": [
    "# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69312276",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohttp==3.9.5\r\n",
      "aiosignal==1.3.1\r\n",
      "alpha-vantage==2.3.1\r\n",
      "annotated-types==0.6.0\r\n",
      "anyio==3.7.1\r\n",
      "appdirs==1.4.4\r\n",
      "appnope==0.1.4\r\n",
      "argon2-cffi @ file:///wheels/argon2_cffi-23.1.0-py3-none-any.whl#sha256=c670642b78ba29641818ab2e68bd4e6a78ba53b7eff7b4c3815ae16abf91c7ea\r\n",
      "argon2-cffi-bindings @ file:///wheels/argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=b746dba803a79238e925d9046a63aa26bf86ab2a2fe74ce6b009a1c3f5c8f2ae\r\n",
      "arrow==1.3.0\r\n",
      "asttokens @ file:///wheels/asttokens-2.4.1-py2.py3-none-any.whl#sha256=051ed49c3dcae8913ea7cd08e46a606dba30b79993209636c4875bc1d637bc24\r\n",
      "attrs @ file:///wheels/attrs-23.2.0-py3-none-any.whl#sha256=99b87a485a5820b23b879f04c2305b44b951b502fd64be915879d77a7e8fc6f1\r\n",
      "beautifulsoup4 @ file:///wheels/beautifulsoup4-4.12.3-py3-none-any.whl#sha256=b80878c9f40111313e55da8ba20bdba06d8fa3969fc68304167741bbf9e082ed\r\n",
      "bleach @ file:///wheels/bleach-6.1.0-py3-none-any.whl#sha256=3225f354cfc436b9789c66c4ee030194bee0568fbf9cbdad3bc8b5c26c5f12b6\r\n",
      "certifi==2024.2.2\r\n",
      "cffi @ file:///wheels/cffi-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=7b78010e7b97fef4bee1e896df8a4bbb6712b7f05b7ef630f9d1da00f6444d2e\r\n",
      "charset-normalizer==3.3.2\r\n",
      "chess==1.10.0\r\n",
      "click==8.1.7\r\n",
      "comm @ file:///wheels/comm-0.2.2-py3-none-any.whl#sha256=e6fb86cb70ff661ee8c9c14e7d36d6de3b4066f1441be4063df9c5009f0a64d3\r\n",
      "contourpy==1.2.1\r\n",
      "cycler==0.12.1\r\n",
      "debugpy @ file:///wheels/debugpy-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=fd97ed11a4c7f6d042d320ce03d83b20c3fb40da892f994bc041bbc415d7a099\r\n",
      "decorator @ file:///wheels/decorator-5.1.1-py3-none-any.whl#sha256=b8c3f85900b9dc423225913c5aace94729fe1fa9763b38939a95226f02d37186\r\n",
      "defusedxml @ file:///wheels/defusedxml-0.7.1-py2.py3-none-any.whl#sha256=a352e7e428770286cc899e2542b6cdaedb2b4953ff269a210103ec58f6198a61\r\n",
      "diskcache==5.6.3\r\n",
      "distro==1.9.0\r\n",
      "docker==7.0.0\r\n",
      "entrypoints==0.4\r\n",
      "executing @ file:///wheels/executing-2.0.1-py2.py3-none-any.whl#sha256=eac49ca94516ccc753f9fb5ce82603156e590b27525a8bc32cce8ae302eb61bc\r\n",
      "fastjsonschema @ file:///wheels/fastjsonschema-2.19.1-py3-none-any.whl#sha256=3672b47bc94178c9f23dbb654bf47440155d4db9df5f7bc47643315f9c405cd0\r\n",
      "FLAML==2.1.2\r\n",
      "fonttools==4.51.0\r\n",
      "fqdn==1.5.1\r\n",
      "frozendict==2.4.4\r\n",
      "frozenlist==1.4.1\r\n",
      "h11==0.14.0\r\n",
      "html5lib==1.1\r\n",
      "httpcore==1.0.5\r\n",
      "httpx==0.27.0\r\n",
      "idna==3.7\r\n",
      "install @ file:///wheels/install-1.3.5-py3-none-any.whl#sha256=0d3fadf4aa62c95efe8d34757c8507eb46177f86c016c21c6551eafc6a53d5a9\r\n",
      "ipykernel @ file:///wheels/ipykernel-6.29.4-py3-none-any.whl#sha256=1181e653d95c6808039c509ef8e67c4126b3b3af7781496c7cbfb5ed938a27da\r\n",
      "ipython==8.18.1\r\n",
      "ipython-genutils @ file:///wheels/ipython_genutils-0.2.0-py2.py3-none-any.whl#sha256=72dd37233799e619666c9f639a9da83c34013a73e8bbc79a7a6348d93c61fab8\r\n",
      "ipywidgets==8.1.0\r\n",
      "isoduration==20.11.0\r\n",
      "jedi @ file:///wheels/jedi-0.19.1-py2.py3-none-any.whl#sha256=e983c654fe5c02867aef4cdfce5a2fbb4a50adc0af145f70504238f18ef5e7e0\r\n",
      "Jinja2 @ file:///wheels/jinja2-3.1.4-py3-none-any.whl#sha256=bc5dd2abb727a5319567b7a813e6a2e7318c39f4f487cfe6c89c6f9c7d25197d\r\n",
      "jsonpointer==2.4\r\n",
      "jsonschema @ file:///wheels/jsonschema-4.22.0-py3-none-any.whl#sha256=ff4cfd6b1367a40e7bc6411caec72effadd3db0bbe5017de188f2d6108335802\r\n",
      "jsonschema-specifications @ file:///wheels/jsonschema_specifications-2023.12.1-py3-none-any.whl#sha256=87e4fdf3a94858b8a2ba2778d9ba57d8a9cafca7c7489c46ba0d30a8bc6a9c3c\r\n",
      "jupyter-client==7.3.2\r\n",
      "jupyter-events==0.10.0\r\n",
      "jupyter_core @ file:///wheels/jupyter_core-5.7.2-py3-none-any.whl#sha256=4f7315d2f6b4bcf2e3e7cb6e46772eba760ae459cd1f59d29eb57b0a01bd7409\r\n",
      "jupyter_server @ file:///wheels/jupyter_server-2.14.0-py3-none-any.whl#sha256=fb6be52c713e80e004fac34b35a0990d6d36ba06fd0a2b2ed82b899143a64210\r\n",
      "jupyter_server_terminals @ file:///wheels/jupyter_server_terminals-0.4.4-py3-none-any.whl#sha256=75779164661cec02a8758a5311e18bb8eb70c4e86c6b699403100f1585a12a36\r\n",
      "jupyterlab_pygments @ file:///wheels/jupyterlab_pygments-0.3.0-py3-none-any.whl#sha256=841a89020971da1d8693f1a99997aefc5dc424bb1b251fd6322462a1b8842780\r\n",
      "jupyterlab_widgets==3.0.10\r\n",
      "kiwisolver==1.4.5\r\n",
      "lxml==5.2.2\r\n",
      "Markdown @ file:///wheels/Markdown-3.4.3-py3-none-any.whl#sha256=065fd4df22da73a625f14890dd77eb8040edcbd68794bcd35943be14490608b2\r\n",
      "markdown-it-py==3.0.0\r\n",
      "MarkupSafe @ file:///wheels/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=b91c037585eba9095565a3556f611e3cbfaa42ca1e865f7b8015fe5c7336d5a5\r\n",
      "matplotlib==3.9.0\r\n",
      "matplotlib-inline @ file:///wheels/matplotlib_inline-0.1.7-py3-none-any.whl#sha256=df192d39a4ff8f21b1895d72e6a13f5fcc5099f00fa84384e0ea28c2cc0653ca\r\n",
      "mdurl==0.1.2\r\n",
      "mistune @ file:///wheels/mistune-3.0.2-py3-none-any.whl#sha256=71481854c30fdbc938963d3605b72501f5c10a9320ecd412c121c163a1c7d205\r\n",
      "multidict==6.0.5\r\n",
      "multitasking==0.0.11\r\n",
      "nbclient @ file:///wheels/nbclient-0.10.0-py3-none-any.whl#sha256=f13e3529332a1f1f81d82a53210322476a168bb7090a0289c795fe9cc11c9d3f\r\n",
      "nbconvert @ file:///wheels/nbconvert-7.16.4-py3-none-any.whl#sha256=05873c620fe520b6322bf8a5ad562692343fe3452abda5765c7a34b7d1aa3eb3\r\n",
      "nbformat @ file:///wheels/nbformat-5.10.4-py3-none-any.whl#sha256=3b48d6c8fbca4b299bf3982ea7db1af21580e4fec269ad087b9e81588891200b\r\n",
      "nest-asyncio @ file:///wheels/nest_asyncio-1.6.0-py3-none-any.whl#sha256=87af6efd6b5e897c81050477ef65c62e2b2f35d51703cae01aff2905b1852e1c\r\n",
      "notebook @ file:///wheels/notebook-6.4.13.dev0-py3-none-any.whl#sha256=1fb7980e0427c262ae37de8bb1f1c85f1da337817f2d1f5cc1967707db087cc5\r\n",
      "numpy==1.26.4\r\n",
      "openai==1.30.1\r\n",
      "overrides==7.7.0\r\n",
      "packaging @ file:///wheels/packaging-24.0-py3-none-any.whl#sha256=2ddfb553fdf02fb784c234c7ba6ccc288296ceabec964ad2eae3777778130bc5\r\n",
      "pandas==2.2.2\r\n",
      "pandas-datareader==0.10.0\r\n",
      "pandocfilters @ file:///wheels/pandocfilters-1.5.1-py2.py3-none-any.whl#sha256=93be382804a9cdb0a7267585f157e5d1731bbe5545a85b268d6f5fe6232de2bc\r\n",
      "parso @ file:///wheels/parso-0.8.4-py2.py3-none-any.whl#sha256=a418670a20291dacd2dddc80c377c5c3791378ee1e8d12bffc35420643d43f18\r\n",
      "peewee==3.17.5\r\n",
      "pexpect @ file:///wheels/pexpect-4.9.0-py2.py3-none-any.whl#sha256=7236d1e080e4936be2dc3e326cec0af72acf9212a7e1d060210e70a47e253523\r\n",
      "pillow==10.3.0\r\n",
      "platformdirs @ file:///wheels/platformdirs-4.2.2-py3-none-any.whl#sha256=2d7a1657e36a80ea911db832a8a6ece5ee53d8de21edd5cc5879af6530b1bfee\r\n",
      "prometheus_client @ file:///wheels/prometheus_client-0.20.0-py3-none-any.whl#sha256=cde524a85bce83ca359cc837f28b8c0db5cac7aa653a588fd7e84ba061c329e7\r\n",
      "prompt-toolkit==3.0.43\r\n",
      "psutil @ file:///wheels/psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=d06016f7f8625a1825ba3732081d77c94589dca78b7a3fc072194851e88461a4\r\n",
      "ptyprocess @ file:///wheels/ptyprocess-0.7.0-py2.py3-none-any.whl#sha256=4b41f3967fce3af57cc7e94b888626c18bf37a083e3651ca8feeb66d492fef35\r\n",
      "pure-eval @ file:///wheels/pure_eval-0.2.2-py3-none-any.whl#sha256=01eaab343580944bc56080ebe0a674b39ec44a945e6d09ba7db3cb8cec289350\r\n",
      "pyautogen==0.2.25\r\n",
      "pycparser @ file:///wheels/pycparser-2.22-py3-none-any.whl#sha256=c3702b6d3dd8c7abc1afa565d7e63d53a1d0bd86cdc24edd75470f4de499cfcc\r\n",
      "pydantic==2.7.1\r\n",
      "pydantic_core==2.18.2\r\n",
      "Pygments @ file:///wheels/pygments-2.18.0-py3-none-any.whl#sha256=b8e6aca0523f3ab76fee51799c488e38782ac06eafcf95e7ba832985c8e7b13a\r\n",
      "pyparsing==3.1.2\r\n",
      "python-dateutil @ file:///wheels/python_dateutil-2.9.0.post0-py2.py3-none-any.whl#sha256=a8b2bc7bffae282281c8140a97d3aa9c14da0b136dfe83f850eea9a5f7470427\r\n",
      "python-dotenv @ file:///wheels/python_dotenv-1.0.1-py3-none-any.whl#sha256=f7b63ef50f1b690dddf550d03497b66d609393b40b564ed0d674909a68ebf16a\r\n",
      "python-json-logger @ file:///wheels/python_json_logger-2.0.7-py3-none-any.whl#sha256=f380b826a991ebbe3de4d897aeec42760035ac760345e57b812938dc8b35e2bd\r\n",
      "pytz==2024.1\r\n",
      "PyYAML @ file:///wheels/PyYAML-6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=432557aa2c09802be39460360ddffd48156e30721f5e8d917f01d31694216782\r\n",
      "pyzmq @ file:///wheels/pyzmq-26.0.3-cp311-cp311-manylinux_2_28_x86_64.whl#sha256=ac97a21de3712afe6a6c071abfad40a6224fd14fa6ff0ff8d0c6e6cd4e2f807a\r\n",
      "redlines==0.4.2\r\n",
      "referencing @ file:///wheels/referencing-0.35.1-py3-none-any.whl#sha256=eda6d3234d62814d1c64e305c1331c9a3a6132da475ab6382eaa997b21ee75de\r\n",
      "regex==2024.5.15\r\n",
      "requests==2.31.0\r\n",
      "rfc3339-validator==0.1.4\r\n",
      "rfc3986-validator==0.1.1\r\n",
      "rich==13.7.1\r\n",
      "rich-click==1.8.2\r\n",
      "rpds-py @ file:///wheels/rpds_py-0.18.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=3c20f05e8e3d4fc76875fc9cb8cf24b90a63f5a1b4c5b9273f0e8225e169b100\r\n",
      "Send2Trash @ file:///wheels/Send2Trash-1.8.3-py3-none-any.whl#sha256=0c31227e0bd08961c7665474a3d1ef7193929fedda4233843689baa056be46c9\r\n",
      "six @ file:///wheels/six-1.16.0-py2.py3-none-any.whl#sha256=8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254\r\n",
      "sniffio==1.3.1\r\n",
      "soupsieve @ file:///wheels/soupsieve-2.5-py3-none-any.whl#sha256=eaa337ff55a1579b6549dc679565eac1e3d000563bcb1c8ab0d0fefbc0c2cdc7\r\n",
      "stack-data @ file:///wheels/stack_data-0.6.3-py3-none-any.whl#sha256=d5558e0c25a4cb0853cddad3d77da9891a08cb85dd9f9f91b9f8cd66e511e695\r\n",
      "termcolor==2.4.0\r\n",
      "terminado @ file:///wheels/terminado-0.18.1-py3-none-any.whl#sha256=a4468e1b37bb318f8a86514f65814e1afc977cf29b3992a4500d9dd305dcceb0\r\n",
      "tiktoken==0.7.0\r\n",
      "tinycss2 @ file:///wheels/tinycss2-1.3.0-py3-none-any.whl#sha256=54a8dbdffb334d536851be0226030e9505965bb2f30f21a4a82c55fb2a80fae7\r\n",
      "tornado==6.1\r\n",
      "tqdm==4.66.4\r\n",
      "traitlets==5.9.0\r\n",
      "types-python-dateutil==2.9.0.20240316\r\n",
      "typing_extensions==4.11.0\r\n",
      "tzdata==2024.1\r\n",
      "uri-template==1.3.0\r\n",
      "urllib3==2.2.1\r\n",
      "wcwidth @ file:///wheels/wcwidth-0.2.13-py2.py3-none-any.whl#sha256=3da69048e4540d84af32131829ff948f1e022c1c6bdb8d6102117aac784f6859\r\n",
      "webcolors==1.13\r\n",
      "webencodings @ file:///wheels/webencodings-0.5.1-py2.py3-none-any.whl#sha256=a0af1213f3c2226497a97e2b3aa01a7e4bee4f403f95be16fc9acd2947514a78\r\n",
      "websocket-client==1.8.0\r\n",
      "widgetsnbextension==4.0.10\r\n",
      "yarl==1.9.4\r\n",
      "yfinance==0.2.38\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cf649",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d006c1-22fa-40ea-b3e0-d543142e0788",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from utils import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a1c4d",
   "metadata": {},
   "source": [
    "## Define an AutoGen agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's one for you: Why don't scientists trust atoms? Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm here to help! Just let me know how I can assist you today.\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98a301",
   "metadata": {},
   "source": [
    "## Conversation\n",
    "\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f71a61",
   "metadata": {},
   "source": [
    "**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe, always ready to bring on the laughs! So I recently started doing yoga to de-stress, but I think I might be doing it wrong because instead of feeling zen, I just feel like a confused pretzel.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Well, Cathy, don't worry, I hear pretzels are very flexible.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, true! Maybe I'm just on the road to becoming a yoga master AND a snack at the same time. Talk about multitasking!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edc810",
   "metadata": {},
   "source": [
    "## Print some results\n",
    "\n",
    "You can print out:\n",
    "\n",
    "1. Chat history\n",
    "2. Cost\n",
    "3. Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Hey Joe, always ready to bring on the laughs! So I recently '\n",
      "             'started doing yoga to de-stress, but I think I might be doing it '\n",
      "             'wrong because instead of feeling zen, I just feel like a '\n",
      "             'confused pretzel.',\n",
      "  'role': 'user'},\n",
      " {'content': \"Well, Cathy, don't worry, I hear pretzels are very flexible.\",\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Haha, true! Maybe I'm just on the road to becoming a yoga master \"\n",
      "             'AND a snack at the same time. Talk about multitasking!',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 93,\n",
      "                                                             'cost': 0.0002605,\n",
      "                                                             'prompt_tokens': 242,\n",
      "                                                             'total_tokens': 335},\n",
      "                                      'total_cost': 0.0002605},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 93,\n",
      "                                                             'cost': 0.0002605,\n",
      "                                                             'prompt_tokens': 242,\n",
      "                                                             'total_tokens': 335},\n",
      "                                      'total_cost': 0.0002605}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Haha, true! Maybe I'm just on the road to becoming a yoga master AND a snack \"\n",
      " 'at the same time. Talk about multitasking!')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c6cf8",
   "metadata": {},
   "source": [
    "## Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe, always ready to bring on the laughs! So I recently started doing yoga to de-stress, but I think I might be doing it wrong because instead of feeling zen, I just feel like a confused pretzel.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Well, Cathy, don't worry, I hear pretzels are very flexible.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, true! Maybe I'm just on the road to becoming a yoga master AND a snack at the same time. Talk about multitasking!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cathy humorously jokes about feeling like a confused pretzel while doing '\n",
      " 'yoga, and Joe light-heartedly suggests that pretzels are flexible, leading '\n",
      " 'to the idea of multitasking as a yoga master and a snack.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300525bd",
   "metadata": {},
   "source": [
    "## Chat Termination\n",
    "\n",
    "Chat can be terminated using a termination conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a classic one, Cathy! I love a good corny joke. How about this one: Why don't some couples go to the gym? Because some relationships don't work out!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a good one, Joe! Here's another one for you: Why did the math book look sad? Because it had too many problems!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, I love it, Cathy! Here's one for you: Why did the tomato turn red? Because it saw the salad dressing!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a juicy one, Joe! How about this one: Why did the golfer bring two pairs of pants? In case he got a hole-in-one!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a hole-in-one joke, Cathy! I love it. Thanks for the laughs. But I gotta go now. Have a great day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "We talked about the golfer bringing two pairs of pants in case he got a hole-in-one!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's right! Thanks for the laughs, Joe. Have a great day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "You're welcome, Cathy! Have a wonderful day too! If you ever need more jokes, just let me know. Take care!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
